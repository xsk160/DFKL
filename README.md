# DRKL
This is the code for the paper "Decoupled Reverse Kullback-Leibler: Rethinking Knowledge Distillation Loss for Bridging GNNs and MLPs"
